{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from math import sqrt\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.offsetbox import TextArea, AnnotationBbox, OffsetImage\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.layers import Input, Conv2D, Conv2DTranspose, MaxPool2D, Dense, Flatten, Reshape\n",
    "from tensorflow.keras.models import Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fashion_mnist = keras.datasets.fashion_mnist\n",
    "(train_images, train_labels), (test_images, test_labels) = fashion_mnist.load_data()\n",
    "class_names = ['T-shirt/top', 'Trouser', 'Pullover', 'Dress', 'Coat',\n",
    "               'Sandal', 'Shirt', 'Sneaker', 'Bag', 'Ankle boot']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,10))\n",
    "for i in range(25):\n",
    "    plt.subplot(5,5,i+1)\n",
    "    plt.xticks([])\n",
    "    plt.yticks([])\n",
    "    plt.grid(False)\n",
    "    plt.imshow(train_images[i], cmap=plt.cm.binary)\n",
    "    plt.xlabel(class_names[train_labels[i]])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_images = train_images / 255.0\n",
    "test_images = test_images / 255.0\n",
    "\n",
    "train_images = np.expand_dims(train_images, -1)\n",
    "test_images = np.expand_dims(test_images, -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_encoder(input_shape, encoding_dim):\n",
    "    inputs = Input(shape=input_shape)\n",
    "    conv1 = Conv2D(32, 3, padding=\"same\", activation=\"relu\")(inputs)\n",
    "    pool1 = MaxPool2D()(conv1)\n",
    "    conv2 = Conv2D(64, 3, padding=\"same\", activation=\"relu\")(pool1)\n",
    "    pool2 = MaxPool2D()(conv2)\n",
    "    flatten = Flatten()(pool2)\n",
    "    dense = Dense(encoding_dim, activation=\"softmax\")(flatten)\n",
    "    \n",
    "    encoder = Model(inputs, dense)\n",
    "    encoder.summary()\n",
    "    \n",
    "    return encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_decoder(encoding_dim):\n",
    "    if not sqrt(encoding_dim).is_integer():\n",
    "        raise ValueError(\"Encoding dim must be a perfect square.\")\n",
    "    \n",
    "    inputs = Input(shape=encoding_dim)\n",
    "    reshape = Reshape((int(sqrt(encoding_dim)), int(sqrt(encoding_dim)), 1))(inputs)\n",
    "    conv1 = Conv2DTranspose(64, 3, strides=2, padding=\"same\", activation=\"relu\")(reshape)\n",
    "    conv2 = Conv2DTranspose(32, 3, strides=2, padding=\"same\", activation=\"relu\")(conv1)\n",
    "    conv3 = Conv2D(1, 3, padding=\"same\", activation=\"sigmoid\")(conv2)\n",
    "    \n",
    "    decoder = Model(inputs, conv3)\n",
    "    decoder.summary()\n",
    "    \n",
    "    return decoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_shape = train_images[0].shape\n",
    "encoding_dim = 49"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder = create_encoder(input_shape, encoding_dim)\n",
    "decoder = create_decoder(encoding_dim)\n",
    "\n",
    "inputs = Input(shape=input_shape)\n",
    "encoded = encoder(inputs)\n",
    "decoded = decoder(encoded)\n",
    "\n",
    "autoencoder = Model(inputs, decoded)\n",
    "autoencoder.summary()\n",
    "\n",
    "autoencoder.compile(optimizer=\"adam\", loss=\"mse\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "autoencoder.fit(train_images, train_images, batch_size=256, epochs=250)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_loss = autoencoder.evaluate(test_images, test_images, batch_size=256)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "visual = test_images[:5]\n",
    "preds = autoencoder.predict(visual)\n",
    "plt.figure(figsize=(10,10))\n",
    "for i in range(5):\n",
    "    plt.subplot(5,5,i+1)\n",
    "    plt.xticks([])\n",
    "    plt.yticks([])\n",
    "    plt.grid(False)\n",
    "    plt.imshow(test_images[i].squeeze(), cmap=plt.cm.binary)\n",
    "    plt.xlabel(\"Original\")\n",
    "for i in range(5):\n",
    "    plt.subplot(5,5,i+6)\n",
    "    plt.xticks([])\n",
    "    plt.yticks([])\n",
    "    plt.grid(False)\n",
    "    plt.imshow(preds[i].squeeze(), cmap=plt.cm.binary)\n",
    "    plt.xlabel(\"Reconstructed\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_latent(mode, count):\n",
    "    idx = np.random.choice(len(test_images), count)\n",
    "    inputs = test_images[idx]\n",
    "    fig, ax = plt.subplots(figsize=(10, 7))\n",
    "    ax.set_title(\"Autoencoder Latent Space\")\n",
    "    coords = encoder.predict(inputs)[:, :2]\n",
    "    \n",
    "    if mode == 'imgs':\n",
    "        for image, (x, y) in zip(inputs, coords):\n",
    "            im = OffsetImage(image.reshape(28, 28), zoom=1, cmap='gray')\n",
    "            ab = AnnotationBbox(im, (x, y), xycoords='data', frameon=False)\n",
    "            ax.add_artist(ab)\n",
    "        ax.update_datalim(coords)\n",
    "        ax.autoscale()\n",
    "    elif mode == 'dots':\n",
    "        classes = test_labels[idx]\n",
    "        plt.scatter(coords[:, 0], coords[:, 1], c=classes)\n",
    "        plt.colorbar()\n",
    "        for i in range(10):\n",
    "            class_center = np.mean(coords[classes == i], axis=0)\n",
    "            text = TextArea('{} ({})'.format(class_names[i], i))\n",
    "            ab = AnnotationBbox(text, class_center, xycoords='data', frameon=True)\n",
    "            ax.add_artist(ab)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_latent(\"dots\", 10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "plot_latent(\"imgs\", 1000)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
